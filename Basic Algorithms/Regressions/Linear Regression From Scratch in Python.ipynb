{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We will implement stochastic gradient descent to optimize a linear regression algorithm from scratch with Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Linear regression is a technique where a straight line is used to model the relationship between input and output values. In more than two dimensions, this straight line may be thought of as a plane or hyperplane. Predictions are made as a combination of the input values to predict the output value. Each input attribute (x) is weighted using a coefficient (b), and the goal of the learning algorithm is to discover a set of coefficients that results in good predictions (y)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a prediction with coefficients\n",
    "def predict(row, coefficients):\n",
    "\tyhat = coefficients[0]\n",
    "\tfor i in range(len(row)-1):\n",
    "\t\tyhat += coefficients[i + 1] * row[i]\n",
    "\treturn yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected=1.000, Predicted=1.200\n",
      "Expected=3.000, Predicted=2.000\n",
      "Expected=3.000, Predicted=3.600\n",
      "Expected=2.000, Predicted=2.800\n",
      "Expected=5.000, Predicted=4.400\n"
     ]
    }
   ],
   "source": [
    "dataset = [[1, 1], [2, 3], [4, 3], [3, 2], [5, 5]]\n",
    "coef = [0.4, 0.8]\n",
    "for row in dataset:\n",
    "\tyhat = predict(row, coef)\n",
    "\tprint(\"Expected=%.3f, Predicted=%.3f\" % (row[-1], yhat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Estimating Coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate linear regression coefficients using stochastic gradient descent\n",
    "def coefficients_sgd(train, l_rate, n_epoch):\n",
    "\tcoef = [0.0 for i in range(len(train[0]))]\n",
    "\tfor epoch in range(n_epoch):\n",
    "\t\tsum_error = 0\n",
    "\t\tfor row in train:\n",
    "\t\t\tyhat = predict(row, coef)\n",
    "\t\t\terror = yhat - row[-1]\n",
    "\t\t\tsum_error += error**2\n",
    "\t\t\tcoef[0] = coef[0] - l_rate * error\n",
    "\t\t\tfor i in range(len(row)-1):\n",
    "\t\t\t\tcoef[i + 1] = coef[i + 1] - l_rate * error * row[i]\n",
    "\t\tprint('>epoch=%d, lrate=%.3f, error=%.3f' % (epoch, l_rate, sum_error))\n",
    "\treturn coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">epoch=0, lrate=0.001, error=46.236\n",
      ">epoch=1, lrate=0.001, error=41.305\n",
      ">epoch=2, lrate=0.001, error=36.930\n",
      ">epoch=3, lrate=0.001, error=33.047\n",
      ">epoch=4, lrate=0.001, error=29.601\n",
      ">epoch=5, lrate=0.001, error=26.543\n",
      ">epoch=6, lrate=0.001, error=23.830\n",
      ">epoch=7, lrate=0.001, error=21.422\n",
      ">epoch=8, lrate=0.001, error=19.285\n",
      ">epoch=9, lrate=0.001, error=17.389\n",
      ">epoch=10, lrate=0.001, error=15.706\n",
      ">epoch=11, lrate=0.001, error=14.213\n",
      ">epoch=12, lrate=0.001, error=12.888\n",
      ">epoch=13, lrate=0.001, error=11.712\n",
      ">epoch=14, lrate=0.001, error=10.668\n",
      ">epoch=15, lrate=0.001, error=9.742\n",
      ">epoch=16, lrate=0.001, error=8.921\n",
      ">epoch=17, lrate=0.001, error=8.191\n",
      ">epoch=18, lrate=0.001, error=7.544\n",
      ">epoch=19, lrate=0.001, error=6.970\n",
      ">epoch=20, lrate=0.001, error=6.461\n",
      ">epoch=21, lrate=0.001, error=6.009\n",
      ">epoch=22, lrate=0.001, error=5.607\n",
      ">epoch=23, lrate=0.001, error=5.251\n",
      ">epoch=24, lrate=0.001, error=4.935\n",
      ">epoch=25, lrate=0.001, error=4.655\n",
      ">epoch=26, lrate=0.001, error=4.406\n",
      ">epoch=27, lrate=0.001, error=4.186\n",
      ">epoch=28, lrate=0.001, error=3.990\n",
      ">epoch=29, lrate=0.001, error=3.816\n",
      ">epoch=30, lrate=0.001, error=3.662\n",
      ">epoch=31, lrate=0.001, error=3.525\n",
      ">epoch=32, lrate=0.001, error=3.404\n",
      ">epoch=33, lrate=0.001, error=3.296\n",
      ">epoch=34, lrate=0.001, error=3.200\n",
      ">epoch=35, lrate=0.001, error=3.115\n",
      ">epoch=36, lrate=0.001, error=3.040\n",
      ">epoch=37, lrate=0.001, error=2.973\n",
      ">epoch=38, lrate=0.001, error=2.914\n",
      ">epoch=39, lrate=0.001, error=2.862\n",
      ">epoch=40, lrate=0.001, error=2.815\n",
      ">epoch=41, lrate=0.001, error=2.773\n",
      ">epoch=42, lrate=0.001, error=2.737\n",
      ">epoch=43, lrate=0.001, error=2.704\n",
      ">epoch=44, lrate=0.001, error=2.675\n",
      ">epoch=45, lrate=0.001, error=2.650\n",
      ">epoch=46, lrate=0.001, error=2.627\n",
      ">epoch=47, lrate=0.001, error=2.607\n",
      ">epoch=48, lrate=0.001, error=2.589\n",
      ">epoch=49, lrate=0.001, error=2.573\n",
      "[0.22998234937311363, 0.8017220304137576]\n"
     ]
    }
   ],
   "source": [
    "# Calculate coefficients\n",
    "dataset = [[1, 1], [2, 3], [4, 3], [3, 2], [5, 5]]\n",
    "l_rate = 0.001\n",
    "n_epoch = 50\n",
    "coef = coefficients_sgd(dataset, l_rate, n_epoch)\n",
    "print(coef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'apt-get' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!apt-get install wget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'wget' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!wget 'http://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-white.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'winequality-white.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-852d160b0ffd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[1;31m# load and prepare data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[0mfilename\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'winequality-white.csv'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 113\u001b[1;33m \u001b[0mdataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    114\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m         \u001b[0mstr_column_to_float\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-852d160b0ffd>\u001b[0m in \u001b[0;36mload_csv\u001b[1;34m(filename)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mload_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0mdataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m         \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m                 \u001b[0mcsv_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcsv_reader\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'winequality-white.csv'"
     ]
    }
   ],
   "source": [
    "# Linear Regression With Stochastic Gradient Descent for Wine Quality\n",
    "from random import seed\n",
    "from random import randrange\n",
    "from csv import reader\n",
    "from math import sqrt\n",
    "\n",
    "# Load a CSV file\n",
    "def load_csv(filename):\n",
    "\tdataset = list()\n",
    "\twith open(filename, 'r') as file:\n",
    "\t\tcsv_reader = reader(file)\n",
    "\t\tfor row in csv_reader:\n",
    "\t\t\tif not row:\n",
    "\t\t\t\tcontinue\n",
    "\t\t\tdataset.append(row)\n",
    "\treturn dataset\n",
    "\n",
    "# Convert string column to float\n",
    "def str_column_to_float(dataset, column):\n",
    "\tfor row in dataset:\n",
    "\t\trow[column] = float(row[column].strip())\n",
    "\n",
    "# Find the min and max values for each column\n",
    "def dataset_minmax(dataset):\n",
    "\tminmax = list()\n",
    "\tfor i in range(len(dataset[0])):\n",
    "\t\tcol_values = [row[i] for row in dataset]\n",
    "\t\tvalue_min = min(col_values)\n",
    "\t\tvalue_max = max(col_values)\n",
    "\t\tminmax.append([value_min, value_max])\n",
    "\treturn minmax\n",
    "\n",
    "# Rescale dataset columns to the range 0-1\n",
    "def normalize_dataset(dataset, minmax):\n",
    "\tfor row in dataset:\n",
    "\t\tfor i in range(len(row)):\n",
    "\t\t\trow[i] = (row[i] - minmax[i][0]) / (minmax[i][1] - minmax[i][0])\n",
    "\n",
    "# Split a dataset into k folds\n",
    "def cross_validation_split(dataset, n_folds):\n",
    "\tdataset_split = list()\n",
    "\tdataset_copy = list(dataset)\n",
    "\tfold_size = int(len(dataset) / n_folds)\n",
    "\tfor i in range(n_folds):\n",
    "\t\tfold = list()\n",
    "\t\twhile len(fold) < fold_size:\n",
    "\t\t\tindex = randrange(len(dataset_copy))\n",
    "\t\t\tfold.append(dataset_copy.pop(index))\n",
    "\t\tdataset_split.append(fold)\n",
    "\treturn dataset_split\n",
    "\n",
    "# Calculate root mean squared error\n",
    "def rmse_metric(actual, predicted):\n",
    "\tsum_error = 0.0\n",
    "\tfor i in range(len(actual)):\n",
    "\t\tprediction_error = predicted[i] - actual[i]\n",
    "\t\tsum_error += (prediction_error ** 2)\n",
    "\tmean_error = sum_error / float(len(actual))\n",
    "\treturn sqrt(mean_error)\n",
    "\n",
    "# Evaluate an algorithm using a cross validation split\n",
    "def evaluate_algorithm(dataset, algorithm, n_folds, *args):\n",
    "\tfolds = cross_validation_split(dataset, n_folds)\n",
    "\tscores = list()\n",
    "\tfor fold in folds:\n",
    "\t\ttrain_set = list(folds)\n",
    "\t\ttrain_set.remove(fold)\n",
    "\t\ttrain_set = sum(train_set, [])\n",
    "\t\ttest_set = list()\n",
    "\t\tfor row in fold:\n",
    "\t\t\trow_copy = list(row)\n",
    "\t\t\ttest_set.append(row_copy)\n",
    "\t\t\trow_copy[-1] = None\n",
    "\t\tpredicted = algorithm(train_set, test_set, *args)\n",
    "\t\tactual = [row[-1] for row in fold]\n",
    "\t\trmse = rmse_metric(actual, predicted)\n",
    "\t\tscores.append(rmse)\n",
    "\treturn scores\n",
    "\n",
    "# Make a prediction with coefficients\n",
    "def predict(row, coefficients):\n",
    "\tyhat = coefficients[0]\n",
    "\tfor i in range(len(row)-1):\n",
    "\t\tyhat += coefficients[i + 1] * row[i]\n",
    "\treturn yhat\n",
    "\n",
    "# Estimate linear regression coefficients using stochastic gradient descent\n",
    "def coefficients_sgd(train, l_rate, n_epoch):\n",
    "\tcoef = [0.0 for i in range(len(train[0]))]\n",
    "\tfor epoch in range(n_epoch):\n",
    "\t\tfor row in train:\n",
    "\t\t\tyhat = predict(row, coef)\n",
    "\t\t\terror = yhat - row[-1]\n",
    "\t\t\tcoef[0] = coef[0] - l_rate * error\n",
    "\t\t\tfor i in range(len(row)-1):\n",
    "\t\t\t\tcoef[i + 1] = coef[i + 1] - l_rate * error * row[i]\n",
    "\t\t\t# print(l_rate, n_epoch, error)\n",
    "\treturn coef\n",
    "\n",
    "# Linear Regression Algorithm With Stochastic Gradient Descent\n",
    "def linear_regression_sgd(train, test, l_rate, n_epoch):\n",
    "\tpredictions = list()\n",
    "\tcoef = coefficients_sgd(train, l_rate, n_epoch)\n",
    "\tfor row in test:\n",
    "\t\tyhat = predict(row, coef)\n",
    "\t\tpredictions.append(yhat)\n",
    "\treturn(predictions)\n",
    "\n",
    "# Linear Regression on wine quality dataset\n",
    "seed(1)\n",
    "# load and prepare data\n",
    "filename = 'winequality-white.csv'\n",
    "dataset = load_csv(filename)\n",
    "for i in range(len(dataset[0])):\n",
    "\tstr_column_to_float(dataset, i)\n",
    "# normalize\n",
    "minmax = dataset_minmax(dataset)\n",
    "normalize_dataset(dataset, minmax)\n",
    "# evaluate algorithm\n",
    "n_folds = 5\n",
    "l_rate = 0.01\n",
    "n_epoch = 50\n",
    "scores = evaluate_algorithm(dataset, linear_regression_sgd, n_folds, l_rate, n_epoch)\n",
    "print('Scores: %s' % scores)\n",
    "print('Mean RMSE: %.3f' % (sum(scores)/float(len(scores))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ref: https://machinelearningmastery.com/implement-linear-regression-stochastic-gradient-descent-scratch-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
